"""Base code for unit testing, including base test classes and variables
describing where to find and save test data, for use by test scripts.
"""
import filecmp
import os
import shutil
import unittest
from datetime import timedelta
from shutil import copyfile
from typing import List, Optional, Collection, Iterable

import numpy as np
import pandas as pd
import gpxpy

from shyft.config import Config
from shyft.activity_manager import ActivityManager

from shyft.activity import ActivityMetaData, Activity
from shyft.df_utils.validate import DataFrameSchema
from shyft.df_utils.schemas import points_schema, laps_splits_km_schema, laps_splits_mile_schema, \
    metadata_summary_schema

TEST_DATA_DIR = os.path.join(os.path.dirname(__file__), 'test_data')
TEST_GPX_FILES_DIR = os.path.join(TEST_DATA_DIR, 'gpx_files')
TEST_FIT_FILES_DIR = os.path.join(TEST_DATA_DIR, 'fit_files')
TEST_TCX_FILES_DIR = os.path.join(TEST_DATA_DIR, 'tcx_files')
TEST_CONFIG_FILE_BASE = os.path.join(TEST_DATA_DIR, 'test_config.ini')
TEST_RUN_DATA_DIR_BASE = os.path.join(TEST_DATA_DIR, 'run')
TEST_ACTIVITY_GRAPHS_FILE = os.path.join(TEST_DATA_DIR, 'test_activity_graphs.json')
TEST_OVERVIEW_GRAPHS_FILE = os.path.join(TEST_DATA_DIR, 'test_overview_graphs.json')

TEST_LOGS_DIR = os.path.join(TEST_RUN_DATA_DIR_BASE, '__logs__')
if not os.path.exists(TEST_LOGS_DIR):
    os.makedirs(TEST_LOGS_DIR)

# Test GPX files.
# Neither 0 nor 1 should loose- or tight-match any other activity.
# 2 and 3 should loose- and tight-match each other but not match any others.
# 4 and 5 should loose- but not tight-match each other.
# TBC if 6 should match 4 or 5.
TEST_GPX_FILES = [
    os.path.join(TEST_GPX_FILES_DIR, 'GNR_2019.gpx'),                   # 0     2019-09-08
    os.path.join(TEST_GPX_FILES_DIR, 'Morning_Run_Miami.gpx'),          # 1     2019-10-30
    os.path.join(TEST_GPX_FILES_DIR, '2020_08_05_pp_9k_ccw.gpx'),       # 2     2020-08-05
    os.path.join(TEST_GPX_FILES_DIR, '2020_08_04_pp_9k_ccw.gpx'),       # 3     2020-08-04
    os.path.join(TEST_GPX_FILES_DIR, '2020_03_20_pp_7.22k_cw.gpx'),     # 4     2020-03-20
    os.path.join(TEST_GPX_FILES_DIR, '2020_06_18_pp_7.23k_ccw.gpx'),    # 5     2020-06-18
    os.path.join(TEST_GPX_FILES_DIR, '2019_07_08_pp_7k_ccw.gpx'),       # 6     2019-07-08
    os.path.join(TEST_GPX_FILES_DIR, 'Calcutta_Run_10k_2019.gpx'),      # 7     2019
    os.path.join(TEST_GPX_FILES_DIR, 'cuilcagh_walk_2019.gpx'),         # 8     2019
    os.path.join(TEST_GPX_FILES_DIR, 'fermanagh_walk_2019.gpx'),        # 9     2019
    os.path.join(TEST_GPX_FILES_DIR, 'Frank_Duffy_10_Mile_2019.gpx'),   # 10    2019
    os.path.join(TEST_GPX_FILES_DIR, 'Great_Ireland_Run_2019.gpx'),     # 11    2019
    os.path.join(TEST_GPX_FILES_DIR, 'howth_walk_2019.gpx'),            # 12    2019
    os.path.join(TEST_GPX_FILES_DIR, 'Irish_Runner_10_Mile_2019.gpx'),  # 13    2019
    os.path.join(TEST_GPX_FILES_DIR, 'run_in_the_dark_10k_2019.gpx'),   # 14    2019
    os.path.join(TEST_GPX_FILES_DIR, 'path_of_gods_walk_2020.gpx'),     # 15    2020-10-11
    os.path.join(TEST_GPX_FILES_DIR, 'amalfi_ironworks_walk_2020.gpx')  # 16    2020-10-13
]

# These have both .gpx and .fit files
FIT_TCX_GPX = (
    '2020_10_03_pp_7k_ccw',
    '2020_11_01_pp_6.84k_ccw',
    '2020_11_07_pp_7.23k_cw',
    'amalfi_ironworks_walk_2020',
    '2020_10_24_pp_7.24k_ccw',
    '2020_11_03_pp_7k_ccw',
    '2020_11_09_pp_7k_ccw',
    'path_of_gods_walk_2020'
)

TEST_GPX_FILES_2 = [os.path.join(TEST_GPX_FILES_DIR, f'{fname}.gpx') for fname in FIT_TCX_GPX]
TEST_FIT_FILES = [os.path.join(TEST_FIT_FILES_DIR, f'{fname}.fit') for fname in FIT_TCX_GPX]
TEST_TCX_FILES = [os.path.join(TEST_TCX_FILES_DIR, f'{fname}.tcx') for fname in FIT_TCX_GPX]

# GPX files generated by Runkeeper
RK_GPX_DIR = os.path.join(TEST_GPX_FILES_DIR, 'runkeeper')
RK_GPX_FILES = [os.path.join(RK_GPX_DIR, f'{fname}.gpx') for fname in FIT_TCX_GPX]

# ints here are index values in TEST_GPX_FILES
LOOSE_MATCH = (
    (2, 3),
    (4, 5)
)

TIGHT_MATCH = (
    (2, 3),
)

UNIQUE = (0, 1, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16)

ACTIVITIES_2019 = (0, 1, 6, 7, 8, 9, 10, 11, 12, 13, 14)
ACTIVITIES_2020 = (2, 3, 4, 5, 15, 16)
ACTIVITIES_2020_08 = (2, 3)


def run_data_dir(name: str, replace: bool = False) -> str:
    data_dir = os.path.join(TEST_RUN_DATA_DIR_BASE, name)
    if replace and os.path.exists(data_dir):
        shutil.rmtree(data_dir)
    os.makedirs(data_dir, exist_ok=True)
    return data_dir

def config_file(run_dir: str) -> str:
    config_fpath = os.path.join(run_dir, 'config.ini')
    copyfile(TEST_CONFIG_FILE_BASE, config_fpath)
    return config_fpath

def get_config(run_dir: str) -> Config:
    conf_file = config_file(run_dir)
    return Config(conf_file, data_dir=run_dir)

def get_manager(config: Config, files: Optional[List[str]] = None) -> ActivityManager:
    manager = ActivityManager(config)
    if files:
        for f in files:
            manager.add_activity_from_file(f)
    return manager

def copy_manager(am: ActivityManager) -> ActivityManager:
    old_config = am.config
    old_data_dir = old_config.data_dir
    i = 0
    new_data_dir = old_data_dir + f'_copy_{i}'
    while os.path.exists(new_data_dir):
        i += 1
        new_data_dir = old_data_dir + f'_copy_{i}'
    config = Config(old_config.ini_fpath, old_config.activity_graphs_fpath, old_config.overview_graphs_fpath,
                    old_config.interpolation, **old_config.kwargs)
    config.data_dir = new_data_dir
    return get_manager(config, files=[a.metadata.source_file for a in am])

class BaseDataFrameValidateTestCase(unittest.TestCase):

    def assert_dataframe_valid(self, df: pd.DataFrame, schema: DataFrameSchema, df_name: str = None):
        """Assert that the given DataFrame conforms to the given
        DataFrameSchema.
        """
        result = schema.validate_dataframe(df)
        if not result.is_valid:
            if df_name is None:
                msg = ['DataFrame does not conform to schema.']
            else:
                msg = [f'DataFrame "{df_name}" does not conform to schema.']
            if result.missing_mandatory_cols:
                col_names = [col.name for col in result.missing_mandatory_cols]
                msg.append(f'Mandatory columns are missing: {", ".join(col_names)}.')
            if result.type_mismatched_cols:
                col_details = []
                for col in result.type_mismatched_cols:
                    actual, expected = result.type_mismatched_cols[col]
                    col_details.append(f'{col.name} ({actual} vs {expected})')
                msg.append(f'Columns are of the wrong dtype: {"; ".join(col_details)}.')
            if result.bad_null_cols:
                col_names = [col.name for col in result.bad_null_cols]
                msg.append(f'Columns contain impermissible null values: {", ".join(col_names)}.')
            if (not schema.extra_cols_ok) and result.extra_col_names:
                msg.append(f'Impermissible extra columns were found: {", ".join(result.extra_col_names)}.')
            if not result.index_name_ok:
                msg.append(f'Bad index name: expected "{schema.index_name}", got "{df.index.name}".')
            if not result.index_type_ok:
                msg.append(f'Index dtype "{df.index.dtype}" is not of type "{schema.index_type}".')
            raise AssertionError(' '.join(msg))

    def assert_dataframe_invalid(self, df: pd.DataFrame, schema: DataFrameSchema):
        """Assert that the given DataFrame does not confirm to the given
        DataFrameSchema.
        """
        self.assertRaises(
            AssertionError,
            lambda: self.assert_dataframe_valid(df, schema)
        )

    def assert_activity_dataframes_valid(self, activity: Activity):
        """Assert that DataFrames associated with the given Activity
        confirm to their respective DataFrameSchemas.
        """
        self.assert_dataframe_valid(activity.points, points_schema, 'points')
        if activity.laps is not None:
            self.assert_dataframe_valid(activity.laps, laps_splits_km_schema, 'laps')
        self.assert_dataframe_valid(activity.km_summary, laps_splits_km_schema, 'km_splits')
        self.assert_dataframe_valid(activity.mile_summary, laps_splits_mile_schema, 'mile_splits')


class BaseTestCase(BaseDataFrameValidateTestCase):

    def assert_timedeltas_almost_equal(self, td1: timedelta, td2: timedelta, places: int = 4):
        self.assertAlmostEqual(td1.total_seconds(), td2.total_seconds(), places)

    def assert_files_equal(self, fpath1: str, fpath2: str):
        self.assertTrue(filecmp.cmp(fpath1, fpath2), f'{fpath1} is not equal to {fpath2}.')

    def assert_metadata_equal(self, md1: ActivityMetaData, md2: ActivityMetaData,
                              almost: bool = False, check_data_files: bool = True, check_types: bool = True,
                              check_elev: bool = True, check_format: bool = True):

        self.assertEqual(md1.activity_id, md2.activity_id,
                         msg=f'Activity IDs are not the same ({md1.activity_id} vs {md2.activity_id}).')
        if check_types:
            self.assertEqual(md1.activity_type, md2.activity_type,
                             msg=f'Activity types are not the same ({md1.activity_type} vs {md2.activity_type}).')
        self.assertEqual(md1.date_time, md2.date_time,
                         msg=f'Activity times are not the same ({md1.date_time} vs {md2.date_time}).')

        if check_elev:
            center1 = md1.center
            center2 = md2.center
            std1 = md1.points_std
            std2 = md2.points_std
        else:
            center1 = md1.center[:2]
            center2 = md2.center[:2]
            std1 = md1.points_std[:2]
            std2 = md2.points_std[:2]

        if almost:
            # NOTE: Tests equality to within 0.5km. Obviously not very satisfactory, but unfortunately the difference
            # between the distance reported by a device and that measured by adding up the haversine distances between
            # points can often be out by as much as a few hundred metres. Possible because of some proprietary
            # adjustment algorithm used by the device.
            self.assertAlmostEqual(md1.distance_2d_km, md2.distance_2d_km, delta=0.5,
                                   msg=f'Activity distances are not the same ({md1.distance_2d_km} vs {md2.distance_2d_km}).')
            np.testing.assert_array_almost_equal(center1, center2, decimal=2)
            np.testing.assert_array_almost_equal(std1, std2, decimal=2)
        else:
            self.assertEqual(md1.distance_2d_km, md2.distance_2d_km,
                             msg=f'Activity distances are not the same ({md1.distance_2d_km} vs {md2.distance_2d_km}).')
            np.testing.assert_array_equal(center1, center2)
            np.testing.assert_array_equal(std1, std2)
        if almost:
            self.assert_timedeltas_almost_equal(md1.mean_km_pace, md2.mean_km_pace, -3)
            self.assert_timedeltas_almost_equal(md1.mean_mile_pace, md2.mean_mile_pace, -3)
            self.assert_timedeltas_almost_equal(md1.duration, md2.duration, -3)
        else:
            self.assert_timedeltas_almost_equal(md1.mean_km_pace, md2.mean_km_pace)
            self.assert_timedeltas_almost_equal(md1.mean_mile_pace, md2.mean_mile_pace)
            self.assert_timedeltas_almost_equal(md1.duration, md2.duration)
        self.assertEqual(md1.prototype_id, md2.prototype_id,
                         msg=f'Prototype IDs are not the same ({md1.prototype_id} vs {md2.prototype_id}).')
        self.assertEqual(md1.name, md2.name,
                         msg=f'Activity names are not the same ({md1.name} vs {md2.name}).')
        self.assertEqual(md1.description, md2.description,
                         msg=f'Activity descriptions are not the same ({md1.description} vs {md2.description}).')
        if check_format:
            self.assertEqual(md1.source_format, md2.source_format)
        if not almost:
            self.assert_files_equal(md1.thumbnail_file, md2.thumbnail_file)
        if check_data_files:
            self.assert_files_equal(md1.gpx_file, md2.gpx_file)

    def assert_activities_equal(self, a1: Activity, a2: Activity, almost: bool = False, check_data_files: bool = True,
                                check_types: bool = True, ignore_points_cols: Optional[List[str]] = None,
                                check_laps: bool = True, check_elev: bool = True, ignore_laps_cols=None,
                                check_format: bool = True):
        # NOTE: If almost is True, comparisons will have a pretty high tolerance of errors. This is mainly to allow
        # rough comparisons between activities generated from different data sources (eg, GPX files vs .FIT files)
        # where differences in precision can lead to differences in distances, etc.

        self.assert_metadata_equal(a1.metadata, a2.metadata, almost=almost, check_data_files=check_data_files,
                                   check_types=check_types, check_elev=check_elev, check_format=check_format)
        if ignore_laps_cols is None:
            ignore_laps_cols = []

        if ignore_points_cols is None:
            ignore_points_cols = []

        if check_laps:
            if (a1.laps is None) or (a2.laps is None):
                self.assertIs(a1.laps, a2.laps)
                points1 = a1.points.drop('lap', axis=1)
                points2 = a2.points.drop('lap', axis=1)
            else:
                if ignore_laps_cols:
                    laps1 = a1.laps.drop(ignore_laps_cols, axis=1)
                    laps2 = a1.laps.drop(ignore_laps_cols, axis=1)
                else:
                    laps1 = a1.laps
                    laps2 = a2.laps
                pd.testing.assert_frame_equal(
                    laps1,
                    laps2,
                    check_like=True,
                    check_dtype=check_types
                )
                points1 = a1.points
                points2 = a2.points
        else:
            points1 = a1.points.drop('lap', axis=1)
            points2 = a2.points.drop('lap', axis=1)

        if check_elev:
            ignore_points_cols.append('elevation')

        if ignore_points_cols:
            points1 = points1.drop(set(ignore_points_cols), axis=1)
            points2 = points2.drop(set(ignore_points_cols), axis=1)
        if almost:
            # Some columns can't really be compared for "almost" equality in the way that we want.
            # So we have to drop these.
            # TODO: Find other ways to compare the dropped columns.
            rtol = 5
            pd.testing.assert_frame_equal(
                points1.drop(['km_pace', 'mile_pace', 'mile', 'km', 'kmph', 'mph'], axis=1),
                points2.drop(['km_pace', 'mile_pace', 'mile', 'km', 'kmph', 'mph'], axis=1),
                check_like=True, rtol=rtol,
                check_dtype=check_types
            )
        else:
            pd.testing.assert_frame_equal(a1.points, a2.points, check_like=True, check_dtype=check_types)

    def assert_metadata_iterable_equal(self, metadata: Iterable[ActivityMetaData], ids: Collection[int],
                                         ordered: bool = False):
        """Assert that an iterable of ActivityMetaData objects contains
        objects with the activity IDs contained in `ids` (and nothing
        else).
        """
        if ordered:
            self.assertListEqual([m.activity_id for m in metadata], list(ids))
        else:
            self.assertSetEqual({m.activity_id for m in metadata}, set(ids))

    def assert_managers_equal(self, manager1: ActivityManager, manager2: ActivityManager, almost: bool = False,
                              check_data_files: bool = True, check_types: bool = True,
                              ignore_points_cols: Optional[List[str]] = None, check_laps: bool = True,
                              check_elev: bool = True, ignore_laps_cols: Optional[List[str]] = None,
                              check_format: bool = True):
        for a1, a2 in zip(manager1, manager2):
            self.assert_activities_equal(a1, a2, almost, check_data_files=check_data_files, check_types=check_types,
                                         ignore_points_cols=ignore_points_cols, check_laps=check_laps,
                                         check_elev=check_elev, ignore_laps_cols=ignore_laps_cols,
                                         check_format=check_format)

    def assert_activity_valid(self, activity: Activity):
        """Assert that the given Activity is valid at a basic level
        (ie, that it broadly contains the minimum amount of data an
        Activity needs to have).
        """
        self.assert_activity_dataframes_valid(activity)
        # TODO: More validation

    def assert_all_activities_valid(self, am: ActivityManager):
        for activity in am:
            self.assert_activity_valid(activity)

    def assert_manager_valid(self, am: ActivityManager):
        """Assert that the given ActivityManager is valid (ie, that all
        its Activities are valid and that it contains the minimum
        amount of data an ActivityManager needs to have.
        """
        self.assert_all_activities_valid(am)
        self.assert_dataframe_valid(am.summarize_metadata(), metadata_summary_schema)
        # TODO: More validation